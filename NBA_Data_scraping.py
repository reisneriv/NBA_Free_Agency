# -*- coding: utf-8 -*-
"""SpursFinalProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1as1d6JlRcquUGvJh5mMqVUqraf8Fm0Nl
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd

# Make a GET request to the website
url = 'https://www.spotrac.com/nba/free-agents/'
response = requests.get(url)

# Parse the HTML content using BeautifulSoup
soup = BeautifulSoup(response.content, 'html.parser')

# Find the table containing the free agents data
table = soup.find('table', class_='datatable')

# Extract the data from the table
data = []
header = []
for i, row in enumerate(table.find_all('tr')):
    if i == 0:
        # Get the header row
        header = [th.text.strip() for th in row.find_all('th')]
    else:
        # Get the data rows
        row_data = [td.text.strip() for td in row.find_all('td')]
        data.append(row_data)

# Create a DataFrame from the extracted data
df = pd.DataFrame(data, columns=header)

# Save the DataFrame to an Excel file
df.to_excel('free_agents_2023.xlsx', index=False)

import requests
from bs4 import BeautifulSoup
import pandas as pd

# Make a GET request to the website
url = 'https://www.spotrac.com/nba/free-agents/2022/'
response = requests.get(url)

# Parse the HTML content using BeautifulSoup
soup = BeautifulSoup(response.content, 'html.parser')

# Find the table containing the free agents data
table = soup.find('table', class_='datatable')

# Extract the data from the table
data = []
header = []
for i, row in enumerate(table.find_all('tr')):
    if i == 0:
        # Get the header row
        header = [th.text.strip() for th in row.find_all('th')]
    else:
        # Get the data rows
        row_data = [td.text.strip() for td in row.find_all('td')]
        data.append(row_data)

# Create a DataFrame from the extracted data
df = pd.DataFrame(data, columns=header)

# Save the DataFrame to an Excel file
df.to_excel('free_agents_2022.xlsx', index=False)

import requests
from bs4 import BeautifulSoup
import pandas as pd

# Make a GET request to the website
url = 'https://www.spotrac.com/nba/free-agents/2021/'
response = requests.get(url)

# Parse the HTML content using BeautifulSoup
soup = BeautifulSoup(response.content, 'html.parser')

# Find the table containing the free agents data
table = soup.find('table', class_='datatable')

# Extract the data from the table
data = []
header = []
for i, row in enumerate(table.find_all('tr')):
    if i == 0:
        # Get the header row
        header = [th.text.strip() for th in row.find_all('th')]
    else:
        # Get the data rows
        row_data = [td.text.strip() for td in row.find_all('td')]
        data.append(row_data)

# Create a DataFrame from the extracted data
df = pd.DataFrame(data, columns=header)

# Save the DataFrame to an Excel file
df.to_excel('free_agents_2021.xlsx', index=False)

import requests
from bs4 import BeautifulSoup
import pandas as pd

# Make a GET request to the website
url = 'https://www.spotrac.com/nba/free-agents/2020/'
response = requests.get(url)

# Parse the HTML content using BeautifulSoup
soup = BeautifulSoup(response.content, 'html.parser')

# Find the table containing the free agents data
table = soup.find('table', class_='datatable')

# Extract the data from the table
data = []
header = []
for i, row in enumerate(table.find_all('tr')):
    if i == 0:
        # Get the header row
        header = [th.text.strip() for th in row.find_all('th')]
    else:
        # Get the data rows
        row_data = [td.text.strip() for td in row.find_all('td')]
        data.append(row_data)

# Create a DataFrame from the extracted data
df = pd.DataFrame(data, columns=header)

# Save the DataFrame to an Excel file
df.to_excel('free_agents_2020.xlsx', index=False)

import requests
from bs4 import BeautifulSoup
import pandas as pd

# Make a GET request to the website
url = 'https://www.spotrac.com/nba/free-agents/2019/'
response = requests.get(url)

# Parse the HTML content using BeautifulSoup
soup = BeautifulSoup(response.content, 'html.parser')

# Find the table containing the free agents data
table = soup.find('table', class_='datatable')

# Extract the data from the table
data = []
header = []
for i, row in enumerate(table.find_all('tr')):
    if i == 0:
        # Get the header row
        header = [th.text.strip() for th in row.find_all('th')]
    else:
        # Get the data rows
        row_data = [td.text.strip() for td in row.find_all('td')]
        data.append(row_data)

# Create a DataFrame from the extracted data
df = pd.DataFrame(data, columns=header)

# Save the DataFrame to an Excel file
df.to_excel('free_agents_2019.xlsx', index=False)

import requests
from bs4 import BeautifulSoup
import pandas as pd

# Make a GET request to the website
url = 'https://www.spotrac.com/nba/free-agents/2018/'
response = requests.get(url)

# Parse the HTML content using BeautifulSoup
soup = BeautifulSoup(response.content, 'html.parser')

# Find the table containing the free agents data
table = soup.find('table', class_='datatable')

# Extract the data from the table
data = []
header = []
for i, row in enumerate(table.find_all('tr')):
    if i == 0:
        # Get the header row
        header = [th.text.strip() for th in row.find_all('th')]
    else:
        # Get the data rows
        row_data = [td.text.strip() for td in row.find_all('td')]
        data.append(row_data)

# Create a DataFrame from the extracted data
df = pd.DataFrame(data, columns=header)

# Save the DataFrame to an Excel file
df.to_excel('free_agents_2018.xlsx', index=False)

import requests
from bs4 import BeautifulSoup
import pandas as pd

# Make a GET request to the website
url = 'https://www.spotrac.com/nba/free-agents/2017/'
response = requests.get(url)

# Parse the HTML content using BeautifulSoup
soup = BeautifulSoup(response.content, 'html.parser')

# Find the table containing the free agents data
table = soup.find('table', class_='datatable')

# Extract the data from the table
data = []
header = []
for i, row in enumerate(table.find_all('tr')):
    if i == 0:
        # Get the header row
        header = [th.text.strip() for th in row.find_all('th')]
    else:
        # Get the data rows
        row_data = [td.text.strip() for td in row.find_all('td')]
        data.append(row_data)

# Create a DataFrame from the extracted data
df = pd.DataFrame(data, columns=header)

# Save the DataFrame to an Excel file
df.to_excel('free_agents_2017.xlsx', index=False)

import requests
from bs4 import BeautifulSoup
import pandas as pd

# Make a GET request to the website
url = 'https://www.spotrac.com/nba/free-agents/2016/'
response = requests.get(url)

# Parse the HTML content using BeautifulSoup
soup = BeautifulSoup(response.content, 'html.parser')

# Find the table containing the free agents data
table = soup.find('table', class_='datatable')

# Extract the data from the table
data = []
header = []
for i, row in enumerate(table.find_all('tr')):
    if i == 0:
        # Get the header row
        header = [th.text.strip() for th in row.find_all('th')]
    else:
        # Get the data rows
        row_data = [td.text.strip() for td in row.find_all('td')]
        data.append(row_data)

# Create a DataFrame from the extracted data
df = pd.DataFrame(data, columns=header)

# Save the DataFrame to an Excel file
df.to_excel('free_agents_2016.xlsx', index=False)

import requests
from bs4 import BeautifulSoup
import pandas as pd

# Send a GET request to the NBA advanced player stats webpage
url = 'https://www.nba.com/stats/players/advanced'
response = requests.get(url)

# Use BeautifulSoup to parse the HTML content of the response
soup = BeautifulSoup(response.content, 'html.parser')

# Find the table containing the advanced player stats
table = soup.find('table', {'class': 'table'})

# Use pandas to read the table into a dataframe
df = pd.read_html(str(table))[0]

# Write the dataframe to an Excel file
df.to_excel('nba_advanced_player_stats.xlsx', index=False)

import requests
from bs4 import BeautifulSoup
import pandas as pd

# Make a GET request to the website
url = 'https://www.basketball-reference.com/leagues/NBA_2023_advanced.html'
response = requests.get(url)

# Parse the HTML content using BeautifulSoup
soup = BeautifulSoup(response.content, 'html.parser')

# Find the table containing the free agents data
table = soup.find('table', class_='datatable')

# Extract the data from the table
data = []
header = []
for i, row in enumerate(table.find_all('tr')):
    if i == 0:
        # Get the header row
        header = [th.text.strip() for th in row.find_all('th')]
    else:
        # Get the data rows
        row_data = [td.text.strip() for td in row.find_all('td')]
        data.append(row_data)

# Create a DataFrame from the extracted data
df = pd.DataFrame(data, columns=header)

# Save the DataFrame to an Excel file
df.to_excel('nbaAdvancedStats.xlsx', index=False)

import requests
from bs4 import BeautifulSoup
import pandas as pd

# Make a GET request to the website
url = 'https://www.spotrac.com/nba/free-agents/2024/ufa/'
response = requests.get(url)

# Parse the HTML content using BeautifulSoup
soup = BeautifulSoup(response.content, 'html.parser')

# Find the table containing the free agents data
table = soup.find('table', class_='datatable')

# Extract the data from the table
data = []
header = []
for i, row in enumerate(table.find_all('tr')):
    if i == 0:
        # Get the header row
        header = [th.text.strip() for th in row.find_all('th')]
    else:
        # Get the data rows
        row_data = [td.text.strip() for td in row.find_all('td')]
        data.append(row_data)

# Create a DataFrame from the extracted data
df = pd.DataFrame(data, columns=header)

# Save the DataFrame to an Excel file
df.to_excel('free_agents_2024.xlsx', index=False)

import requests
from bs4 import BeautifulSoup
import pandas as pd

# Make a GET request to the website
url = 'https://www.spotrac.com/nba/free-agents/2025/ufa/'
response = requests.get(url)

# Parse the HTML content using BeautifulSoup
soup = BeautifulSoup(response.content, 'html.parser')

# Find the table containing the free agents data
table = soup.find('table', class_='datatable')

# Extract the data from the table
data = []
header = []
for i, row in enumerate(table.find_all('tr')):
    if i == 0:
        # Get the header row
        header = [th.text.strip() for th in row.find_all('th')]
    else:
        # Get the data rows
        row_data = [td.text.strip() for td in row.find_all('td')]
        data.append(row_data)

# Create a DataFrame from the extracted data
df = pd.DataFrame(data, columns=header)

# Save the DataFrame to an Excel file
df.to_excel('free_agents_2025.xlsx', index=False)

import requests
from bs4 import BeautifulSoup
import pandas as pd

# Make a GET request to the website
url = 'https://www.spotrac.com/nba/free-agents/2026/ufa/'
response = requests.get(url)

# Parse the HTML content using BeautifulSoup
soup = BeautifulSoup(response.content, 'html.parser')

# Find the table containing the free agents data
table = soup.find('table', class_='datatable')

# Extract the data from the table
data = []
header = []
for i, row in enumerate(table.find_all('tr')):
    if i == 0:
        # Get the header row
        header = [th.text.strip() for th in row.find_all('th')]
    else:
        # Get the data rows
        row_data = [td.text.strip() for td in row.find_all('td')]
        data.append(row_data)

# Create a DataFrame from the extracted data
df = pd.DataFrame(data, columns=header)

# Save the DataFrame to an Excel file
df.to_excel('free_agents_2026.xlsx', index=False)

import requests
from bs4 import BeautifulSoup
import pandas as pd

# Make a GET request to the website
url = 'https://www.nbadraft.net/ranking/bigboard/'
response = requests.get(url)

# Parse the HTML content using BeautifulSoup
soup = BeautifulSoup(response.content, 'html.parser')

# Find the table containing the free agents data
table = soup.find('table', class_='datatable')

# Extract the data from the table
data = []
header = []
for i, row in enumerate(table.find_all('tr')):
    if i == 0:
        # Get the header row
        header = [th.text.strip() for th in row.find_all('th')]
    else:
        # Get the data rows
        row_data = [td.text.strip() for td in row.find_all('td')]
        data.append(row_data)

# Create a DataFrame from the extracted data
df = pd.DataFrame(data, columns=header)

# Save the DataFrame to an Excel file
df.to_excel('draft.xlsx', index=False)